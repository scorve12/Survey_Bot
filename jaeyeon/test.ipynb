{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n다음 아래 코드는 임시 설문지 결과 가정한 것\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example\n",
    "import pandas as pd\n",
    "\n",
    "survey=pd.DataFrame(data=([\n",
    "'나는 다른 사람들이 힘들어하는 것을 볼 때 그들을 구제해 줘야 할 것 같다. 그래서 그들의 문제를 대신 해결해 주려고 애쓴다.'\n",
    ",'나는 다른 사람들이 실수를 하는 것을 볼 때 그들을 지도해 줘야 할 것 같다. 그래서 그들이 어떻게 해야 하는지 말하게 된다.'\n",
    ",'나는 다른사람들을 기쁘게 해줘야 할 것 같다. 그래서 다른사람들이 내가 하기 싫은 일을 시키더라도 가만히 있는다.'\n",
    ",'나는 다른사람들이 나를 진정으로 이해해 주기를 바란다. 그래서 사람들이 내 기분을 잘 몰라주면 상처 받는다.'\n",
    ",'나는 다른사람을 내옆에 둬야 할 것 같다. 그래서 그들이 나를 떠나려 할 때도 내옆에 두기 위해 할 수 있는 어떤 일이라도 하려 한다.'\n",
    ",'나는 다른 사람을 변화시켜야 할 것 같다 그래서 그들이 나와 다른 시념과 가치관을 가지고 있더라도 나와 비슷한 생각을 하도록 부추긴다.'\n",
    ",'나는 다른 사람을 이해시켜야 할 것 같다. 그래서 그다른 사람들이 나와 관점이 다를 땐 화가 나거나 마을 닫게 된다.'\n",
    ",'나는 다른 사람들과 가까워져야 할 것 같다. 그래서 그들이 어느 정도 거리를 두도록 내버려두기 힘들다.'\n",
    ",'나는 다른 사람들의 인정에 괸장히 매달리는 편이다. 그래서 그들이 나를 거부할 때는 상처를 받는다.'\n",
    ",'나는 다른 사람들의 신뢰를 받고 싶다. 그래서 그들이 나를 신뢰하지 않을 때는 거절당했다고 느낀다.'\n",
    ",'나는 누군가를 신뢰하고 싶다. 그래서 그들이 나를 신뢰하지 않을 때는 거절당했다고 느낀다.'\n",
    ",'나는 누군가 나를 수용해 주기를 원한다. 그래서 그 사람이 나를 좋아하지 않을 때는 내 자신이 하찮게 느껴진다.'\n",
    ",'나는 누군가가 나를 보살펴 주기를 원한다. 그래서 그 사람이 나에게 도움이 되지 못한다면 버림받은 것 같다.'\n",
    ",'나는 누군가가가 신뢰할 만한 사람이길 바란다. 그래서 그 사람이 나의 기대를 저버릴 경우 실망한다.'\n",
    ",'나는 다름 사람들이 승인해 주기를 원한다. 그래서 그들이 내가 하려는 일에 반대를 하면 기분이 나쁘다.'\n",
    ",'나는 팩임감에서 벗어나고 싶다. 그래서 내가 관심있는 사람들이라도 나에게 너무 의존하려고 하면 거리를 둔다.'\n",
    ",'나는 다름 사람들의 존경을 받고 싶다. 그래서 사람들이 나를 인정해 주지 않으면 상처를 받는다.'\n",
    ",'나는 다름사람들을 수용하길 원한다. 하지만 그들이 나의 기대에 미치지 못할 땐 거리를 두게 한다.'\n",
    ",'나는 갈들을 피해야 할 것 같다. 그래서 누군가가 나를 함부로 대할 때에도 가만히 있는다.']\n",
    "),columns=['질문사항']\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "다음 아래 코드는 실험을 위한 임시 설문지 결과 가정한 것\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "answer=pd.DataFrame(data=(np.random.randint(0, 2, size=len(survey))),columns=['답변'])\n",
    "\n",
    "survey_answer=pd.concat([survey,answer],axis=1)\n",
    "survey_answer\n",
    "\n",
    "# survey_answer.to_csv('survey_answer.csv', index=False) -->csv에 넣어둠\n",
    "#시나리오\n",
    "#1. 음성 설문지를 봇이 읽어줌 \n",
    "#2. 음성이 나온 후 내담자가 대답을 함 '예' 혹은 '아니오' 이때 간격을 두고 값이 들어오면  다음으로 반복 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey=pd.read_csv(r\"D:\\Project\\Survey_Bot\\CSV\\대인관계 패턴의 자기이해 척도.csv\",index_col=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'texttospeech' from 'google.cloud' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcloud\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m texttospeech\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# OpenAI GPT로부터 텍스트 생성\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_text\u001b[39m(prompt):\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'texttospeech' from 'google.cloud' (unknown location)"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "from google.cloud import texttospeech\n",
    "\n",
    "# OpenAI GPT로부터 텍스트 생성\n",
    "def generate_text(prompt):\n",
    "    openai.api_key = 'your_openai_api_key'\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-003\",  # 사용 가능한 최신 엔진 사용 권장\n",
    "        prompt=prompt,\n",
    "        max_tokens=50\n",
    "    )\n",
    "    return response.choices[0].text.strip()\n",
    "\n",
    "# Google TTS를 사용하여 음성 파일 생성\n",
    "def text_to_speech(text, output_file=\"output.mp3\"):\n",
    "    client = texttospeech.TextToSpeechClient()\n",
    "    synthesis_input = texttospeech.SynthesisInput(text=text)\n",
    "    voice = texttospeech.VoiceSelectionParams(\n",
    "        language_code=\"ko-KR\",\n",
    "        ssml_gender=texttospeech.SsmlVoiceGender.NEUTRAL\n",
    "    )\n",
    "    audio_config = texttospeech.AudioConfig(\n",
    "        audio_encoding=texttospeech.AudioEncoding.MP3\n",
    "    )\n",
    "    response = client.synthesize_speech(\n",
    "        input=synthesis_input,\n",
    "        voice=voice,\n",
    "        audio_config=audio_config\n",
    "    )\n",
    "\n",
    "    # 음성 파일로 저장\n",
    "    with open(output_file, \"wb\") as out:\n",
    "        out.write(response.audio_content)\n",
    "    print(f\"Audio content written to file {output_file}\")\n",
    "\n",
    "# 사용 예시\n",
    "text_generated = generate_text(\"여기에 한국어로 자연스러운 문장을 입력하세요.\")\n",
    "text_to_speech(text_generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\venv\\whisper\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "d:\\venv\\whisper\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 우리가 사용할 대답을 택스트로 받으면 이를 긍정인지 부정인지 판별해줄 모델 -> 그벼움 그리고 결과 리턴도 상당히 빠름\n",
    "from transformers import pipeline\n",
    "classifier = pipeline(\"text-classification\", model=\"matthewburke/korean_sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\venv\\whisper\\Lib\\site-packages\\transformers\\pipelines\\text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 1, 0, 1, 1, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_tweet = ['옳습니다','그런거 같습니다.','아니오','예, 맞습니다.','넵','전혀 아닌거 같습니다','아 ㄴ ㅣㅣ오','잔햐 아니예','아닌거 같수예']\n",
    "\n",
    "preds_list=[]\n",
    "for response in custom_tweet:\n",
    "    preds =classifier(response, return_all_scores=True)\n",
    "    is_positive = preds[0][1]['score'] > 0.5\n",
    "    preds_list.append(is_positive)\n",
    "    \n",
    "[1 if x else 0 for x in preds_list]\n",
    "#1은 '예',0은 '아니오'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, True, False, True, True, False]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "from scipy.io.wavfile import write\n",
    "import whisper\n",
    "import tempfile\n",
    "import os\n",
    "from gtts import gTTS\n",
    "import pandas as pd\n",
    "import time\n",
    "from transformers import pipeline\n",
    "classifier = pipeline(\"text-classification\", model=\"matthewburke/korean_sentiment\")\n",
    "# 설문 데이터 로드\n",
    "survey = pd.read_csv(r\"D:\\Project\\Survey_Bot\\CSV\\대인관계 패턴의 자기이해 척도.csv\", index_col=False)\n",
    "\n",
    "# 녹음 설정\n",
    "sample_rate = 44100  # 녹음 샘플링 비율\n",
    "duration = 5  # 녹음할 시간(초)\n",
    "\n",
    "# Whisper 모델 로드\n",
    "model = whisper.load_model(\"base\")\n",
    "\n",
    "def record_audio():\n",
    "    print(\"녹음을 시작합니다. 말씀해주세요...\")\n",
    "    recording = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=2)\n",
    "    sd.wait()  # 녹음이 끝날 때까지 대기\n",
    "    print(\"녹음이 완료되었습니다.\")\n",
    "\n",
    "    # 임시 파일로 녹음된 오디오 저장\n",
    "    temp_dir = tempfile.mkdtemp()\n",
    "    audio_file = os.path.join(temp_dir, \"recording.wav\")\n",
    "    write(audio_file, sample_rate, recording)  # 녹음된 오디오를 WAV 파일로 저장\n",
    "    \n",
    "    # 오디오 파일 변환 및 텍스트 추출\n",
    "    result = model.transcribe(audio_file)\n",
    "    \n",
    "    # 임시 파일 정리\n",
    "    os.remove(audio_file)\n",
    "    os.rmdir(temp_dir)\n",
    "    \n",
    "    return result[\"text\"]\n",
    "\n",
    "def speak(text):\n",
    "    tts = gTTS(text=text, lang='ko')\n",
    "    temp_dir = tempfile.mkdtemp()\n",
    "    temp_file = os.path.join(temp_dir, \"temp_audio.mp3\")\n",
    "    tts.save(temp_file)\n",
    "    os.system(f\"start {temp_file}\")\n",
    "    time.sleep(len(text) * 0.05 + 1)  # 재생 시간 대기\n",
    "    os.remove(temp_file)\n",
    "    os.rmdir(temp_dir)\n",
    "\n",
    "\n",
    "\n",
    "# 상담 시작\n",
    "speak(\"상담을 시작하겠습니다. 준비가 되셨으면 '네'라고 말씀해 주세요.\")\n",
    "response = record_audio()\n",
    "if \"네\" in response:\n",
    "    for index, row in survey.iterrows():\n",
    "        speak(row['질문사항'])\n",
    "        response = record_audio()\n",
    "        print(f\"받은 대답: {response}\")\n",
    "        # 대답을 처리하거나 저장하는 로직을 여기에 추가하세요.\n",
    "        speak(\"다음 질문으로 넘어갑니다.\")\n",
    "else:\n",
    "    speak(\"상담을 시작하지 않습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['나는 다른 사람들이 실수를 하는 것을 볼 때 그들을 지도해 줘야 할 것 같다. 그래서 그들이 어떻게 해야 하는지 말하게 된다.',\n",
       " '나는 다른사람들을 기쁘게 해줘야 할 것 같다. 그래서 다른사람들이 내가 하기 싫은 일을 시키더라도 가만히 있는다.',\n",
       " '나는 다른사람들이 나를 진정으로 이해해 주기를 바란다. 그래서 사람들이 내 기분을 잘 몰라주면 상처 받는다.',\n",
       " '나는 다른 사람을 이해시켜야 할 것 같다. 그래서 그다른 사람들이 나와 관점이 다를 땐 화가 나거나 마을 닫게 된다.',\n",
       " '나는 다른 사람들의 신뢰를 받고 싶다. 그래서 그들이 나를 신뢰하지 않을 때는 거절당했다고 느낀다.',\n",
       " '나는 누군가를 신뢰하고 싶다. 그래서 그들이 나를 신뢰하지 않을 때는 거절당했다고 느낀다.',\n",
       " '나는 누군가가가 신뢰할 만한 사람이길 바란다. 그래서 그 사람이 나의 기대를 저버릴 경우 실망한다.',\n",
       " '나는 갈들을 피해야 할 것 같다. 그래서 누군가가 나를 함부로 대할 때에도 가만히 있는다.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masking=(survey_answer['답변']==1)\n",
    "docs=survey_answer[masking]['질문사항'].to_list()\n",
    "docs\n",
    "\n",
    "# 도메인 지식이 부족함\n",
    "# 상담사가 위 사항들을 보고 상태보고서를 작성하면 이를 바탕으로 상담심리 논문들을 가져와 서치해서 도움을 주는 방식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TTS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;66;03m# or cuda:0\u001b[39;00m\n\u001b[0;32m      7\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m안녕하세요! 오늘은 날씨가 정말 좋네요.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 8\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mTTS\u001b[49m(language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKR\u001b[39m\u001b[38;5;124m'\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m      9\u001b[0m speaker_ids \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mhps\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mspk2id\n\u001b[0;32m     11\u001b[0m output_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkr.wav\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'TTS' is not defined"
     ]
    }
   ],
   "source": [
    "import melo import TTS\n",
    "\n",
    "# Speed is adjustable\n",
    "speed = 1.0\n",
    "device = 'cpu' # or cuda:0\n",
    "\n",
    "text = \"안녕하세요! 오늘은 날씨가 정말 좋네요.\"\n",
    "model = TTS(language='KR', device=device)\n",
    "speaker_ids = model.hps.data.spk2id\n",
    "\n",
    "output_path = 'kr.wav'\n",
    "model.tts_to_file(text, speaker_ids['KR'], output_path, speed=speed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved audio file for question 0 at tts_audio_0.mp3\n",
      "Saved audio file for question 1 at tts_audio_1.mp3\n",
      "Saved audio file for question 2 at tts_audio_2.mp3\n",
      "Saved audio file for question 3 at tts_audio_3.mp3\n",
      "Saved audio file for question 4 at tts_audio_4.mp3\n",
      "Saved audio file for question 5 at tts_audio_5.mp3\n",
      "Saved audio file for question 6 at tts_audio_6.mp3\n",
      "Saved audio file for question 7 at tts_audio_7.mp3\n",
      "Saved audio file for question 8 at tts_audio_8.mp3\n",
      "Saved audio file for question 9 at tts_audio_9.mp3\n",
      "Saved audio file for question 10 at tts_audio_10.mp3\n",
      "Saved audio file for question 11 at tts_audio_11.mp3\n",
      "Saved audio file for question 12 at tts_audio_12.mp3\n",
      "Saved audio file for question 13 at tts_audio_13.mp3\n",
      "Saved audio file for question 14 at tts_audio_14.mp3\n",
      "Saved audio file for question 15 at tts_audio_15.mp3\n",
      "Saved audio file for question 16 at tts_audio_16.mp3\n",
      "Saved audio file for question 17 at tts_audio_17.mp3\n",
      "Saved audio file for question 18 at tts_audio_18.mp3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "# 환경 변수에서 API 키 불러오기\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = OpenAI(api_key=\"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\")\n",
    "\n",
    "# 음성 파일 경로와 파일 이름 설정\n",
    "audio_file_base_path = \"tts_audio\"\n",
    "\n",
    "# 설문 데이터프레임 로드 (예시: CSV 파일로부터)\n",
    "survey = pd.read_csv(r\"D:\\Project\\Survey_Bot\\CSV\\대인관계 패턴의 자기이해 척도.csv\", index_col=False)\n",
    "\n",
    "# 음성 파일 생성\n",
    "for idx, q in enumerate(survey['질문'].to_list()):\n",
    "    try:\n",
    "        response = client.audio.speech.create(\n",
    "            model=\"tts-1\",\n",
    "            input=q,\n",
    "            voice=\"alloy\",\n",
    "            response_format=\"mp3\",\n",
    "            speed=1.1,\n",
    "        )\n",
    "        # 각 음성 파일을 별도의 파일로 저장\n",
    "        audio_file_path = f\"{audio_file_base_path}_{idx}.mp3\"\n",
    "        with open(audio_file_path, \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "        print(f\"Saved audio file for question {idx} at {audio_file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to create speech for question {idx}: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from playsound import playsound\n",
    "\n",
    "# 음성 파일이 저장된 폴더 경로와 패턴\n",
    "audio_files_pattern = '. \\audio\\*.mp3'\n",
    "\n",
    "# glob을 사용하여 폴더 내의 모든 mp3 파일 목록을 가져옵니다.\n",
    "audio_files = glob.glob(audio_files_pattern)\n",
    "\n",
    "# 모든 음성 파일을 순차적으로 재생\n",
    "for audio_file in audio_files:\n",
    "    print(f\"Playing {audio_file}...\")\n",
    "    playsound(audio_file)\n",
    "    print(f\"Finished playing {audio_file}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.2 (SDL 2.28.3, Python 3.11.5)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\venv\\whisper\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "d:\\venv\\whisper\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "녹음을 시작합니다. 말씀해주세요...\n",
      "녹음이 완료되었습니다.\n",
      "인식된 텍스트:  네 맞습니다\n",
      "녹음을 시작합니다. 말씀해주세요...\n",
      "녹음이 완료되었습니다.\n",
      "인식된 텍스트:  아니요, 전혀.\n",
      " 네 맞습니다\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\venv\\whisper\\Lib\\site-packages\\transformers\\pipelines\\text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 아니요, 전혀.\n"
     ]
    }
   ],
   "source": [
    "import pygame\n",
    "import glob\n",
    "import time\n",
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "from scipy.io.wavfile import write\n",
    "import whisper\n",
    "import tempfile\n",
    "import warnings\n",
    "import os\n",
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"text-classification\", model=\"matthewburke/korean_sentiment\")\n",
    "\n",
    "# pygame 라이브러리 초기화\n",
    "pygame.init()\n",
    "pygame.mixer.init()\n",
    "\n",
    "# 음성 파일이 저장된 폴더 경로와 패턴\n",
    "audio_files_pattern = r'D:\\Project\\Survey_Bot\\audio\\*.mp3'\n",
    "\n",
    "# glob을 사용하여 폴더 내의 모든 mp3 파일 목록을 가져옵니다.\n",
    "audio_files = glob.glob(audio_files_pattern)\n",
    "\n",
    "sample_rate = 44100  # 녹음 샘플링 비율\n",
    "duration = 5  # 녹음할 시간(초)\n",
    "respronse_text=[]\n",
    "\n",
    "# 모든 음성 파일을 순차적으로 재생\n",
    "for audio_file in audio_files[:2]:\n",
    "    #print(f\"Playing {audio_file}...\")\n",
    "    pygame.mixer.music.load(audio_file)\n",
    "    pygame.mixer.music.play()\n",
    "    # 재생이 완료될 때까지 대기\n",
    "    \n",
    "    while pygame.mixer.music.get_busy():\n",
    "        pygame.time.Clock().tick(10)\n",
    "    #print(f\"Finished playing {audio_file}.\")\n",
    "    \n",
    "    print(\"녹음을 시작합니다. 말씀해주세요...\")\n",
    "    recording = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=2)\n",
    "    sd.wait()  # 녹음이 끝날 때까지 대기\n",
    "    print(\"녹음이 완료되었습니다.\")\n",
    "\n",
    "    # 임시 파일로 녹음된 오디오 저장\n",
    "    temp_dir = tempfile.mkdtemp()\n",
    "    audio_file = os.path.join(temp_dir, \"recording.wav\")\n",
    "    write(audio_file, sample_rate, recording)  # 녹음된 오디오를 WAV 파일로 저장\n",
    "\n",
    "    # Whisper 모델 로드 및 오디오 파일 변환\n",
    "    model = whisper.load_model(\"medium\")\n",
    "\n",
    "    #cpu사용자경우 경고 메세지 삭제\n",
    "    warnings.filterwarnings(\"ignore\", message=\"FP16 is not supported on CPU\")\n",
    "\n",
    "    result = model.transcribe(audio_file, fp16=False)\n",
    "\n",
    "\n",
    "    # 결과 출력 및 임시 파일 정리\n",
    "    respronse_text.append(result[\"text\"])\n",
    "    print(\"인식된 텍스트:\", result[\"text\"])\n",
    "    os.remove(audio_file)  # 임시 오디오 파일 삭제\n",
    "    os.rmdir(temp_dir)  # 임시 디렉토리 삭제\n",
    "\n",
    "pred_respronse=[]\n",
    "for r in respronse_text:\n",
    "    print(r)\n",
    "    preds =classifier(r, return_all_scores=True)\n",
    "    is_positive = preds[0][1]['score'] > 0.5\n",
    "    pred_respronse.append(is_positive)\n",
    "    \n",
    "respronse=[1 if x else 0 for x in pred_respronse]\n",
    "\n",
    "respronse\n",
    "\n",
    "# pygame 종료\n",
    "pygame.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_respronse=[]\n",
    "for r in respronse_text:\n",
    "    print(r)\n",
    "    preds =classifier(r, return_all_scores=True)\n",
    "    is_positive = preds[0][1]['score'] > 0.5\n",
    "    pred_respronse.append(is_positive)\n",
    "    \n",
    "respronse=[1 if x else 0 for x in pred_respronse]\n",
    "\n",
    "respronse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "chroma_client = chromadb.Client()\n",
    "collection = chroma_client.create_collection(name=\"papaers\")\n",
    "\n",
    "for doc, idx in zip(docs, range(len(docs))):\n",
    "    collection.add(\n",
    "        documents=[doc],\n",
    "        ids=[f\"id{idx+1}\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"properties\": {\"name\": {\"title\": \"Name\", \"type\": \"string\"}, \"id\": {\"format\": \"uuid\", \"title\": \"Id\", \"type\": \"string\"}, \"metadata\": {\"anyOf\": [{\"type\": \"object\"}, {\"type\": \"null\"}], \"default\": null, \"title\": \"Metadata\"}, \"tenant\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"default\": null, \"title\": \"Tenant\"}, \"database\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"default\": null, \"title\": \"Database\"}}, \"required\": [\"name\", \"id\"], \"title\": \"Collection\", \"type\": \"object\"}'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 필요한 컬렉션을 가져옴\n",
    "collection = chroma_client.get_collection(name=\"survey\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['id5', 'id2', 'id8', 'id4', 'id6']],\n",
       " 'distances': [[0.18667097389698029,\n",
       "   0.21450647711753845,\n",
       "   0.2666412591934204,\n",
       "   0.2700873911380768,\n",
       "   0.3037261366844177]],\n",
       " 'metadatas': [[None, None, None, None, None]],\n",
       " 'embeddings': None,\n",
       " 'documents': [['나는 다른 사람들의 신뢰를 받고 싶다. 그래서 그들이 나를 신뢰하지 않을 때는 거절당했다고 느낀다.',\n",
       "   '나는 다른사람들을 기쁘게 해줘야 할 것 같다. 그래서 다른사람들이 내가 하기 싫은 일을 시키더라도 가만히 있는다.',\n",
       "   '나는 갈들을 피해야 할 것 같다. 그래서 누군가가 나를 함부로 대할 때에도 가만히 있는다.',\n",
       "   '나는 다른 사람을 이해시켜야 할 것 같다. 그래서 그다른 사람들이 나와 관점이 다를 땐 화가 나거나 마을 닫게 된다.',\n",
       "   '나는 누군가를 신뢰하고 싶다. 그래서 그들이 나를 신뢰하지 않을 때는 거절당했다고 느낀다.']],\n",
       " 'uris': None,\n",
       " 'data': None}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.query(\n",
    "    query_texts=[\"나는 다른사람들을 기쁘게 해줘야 할 것 같다.\"],\n",
    "    n_results=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "whisper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
